{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "WDOiZ3cy1jMW"
      },
      "outputs": [],
      "source": [
        "import nltk\n",
        "def ie_preprocess(document):\n",
        "    sentences = nltk.sent_tokenize(document)\n",
        "    sentences = [nltk.word_tokenize(sent) for sent in sentences]\n",
        "    sentences = [nltk.pos_tag(sent) for sent in sentences]\n",
        "    # you could continue the entitty recognation and relation using spacy"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# chuncking\n",
        "# chuncking noum\n",
        "sentence = [(\"the\", \"DT\"), (\"little\", \"JJ\"), (\"yellow\", \"JJ\"),\n",
        " (\"dog\", \"NN\"), (\"barked\", \"VBD\"), (\"at\", \"IN\"), (\"the\", \"DT\"), (\"cat\", \"NN\")]\n",
        "\n",
        "grammar = \"NP: {<DT>?<JJ>*<NN>}\"\n",
        "cp = nltk.RegexpParser(grammar)\n",
        "result = cp.parse(sentence)\n",
        "print(result)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d4DoEOfThBMP",
        "outputId": "f8bb0ea4-9aaf-4cd3-9878-11e320528a69"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(S\n",
            "  (NP the/DT little/JJ yellow/JJ dog/NN)\n",
            "  barked/VBD\n",
            "  at/IN\n",
            "  (NP the/DT cat/NN))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#result.draw()"
      ],
      "metadata": {
        "id": "wNOqLSu5hKUp"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#chuncking regex\n",
        "import re\n",
        "grammar = r\"\"\"\n",
        "    NP: {<DT|PP\\$>?<JJ>*<NN>} # chunk determiner/possessive, adjectives and noun\n",
        "        {<NNP>+}              # chunk sequences of proper nouns\n",
        "\"\"\"\n",
        "cp = nltk.RegexpParser(grammar)\n",
        "sentence = [(\"Rapunzel\", \"NNP\"), (\"let\", \"VBD\"), (\"down\", \"RP\"),\n",
        "            (\"her\", \"PP$\"), (\"long\", \"JJ\"), (\"golden\", \"JJ\"), (\"hair\", \"NN\")]\n",
        "print(cp.parse(sentence))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KNXr8vIxhPOJ",
        "outputId": "246af587-72d3-44f2-c020-feb1896f2681"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(S\n",
            "  (NP Rapunzel/NNP)\n",
            "  let/VBD\n",
            "  down/RP\n",
            "  (NP her/PP$ long/JJ golden/JJ hair/NN))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ouns = [(\"money\", \"NN\"), (\"market\", \"NN\"), (\"fund\", \"NN\")]\n",
        "grammar = \"NP: {<NN><NN>}  # Chunk two consecutive nouns\"\n",
        "cp = nltk.RegexpParser(grammar)\n",
        "print(cp.parse(ouns))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dJ2k8lxmjlIY",
        "outputId": "e0a253a7-9ce5-4232-d891-8931aae48efd"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(S (NP money/NN market/NN) fund/NN)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ouns = [(\"money\", \"NN\"), (\"market\", \"NN\"), (\"fund\", \"NN\")]\n",
        "grammar = \"NP: {<NN>+}  # Chunk two consecutive nouns\"\n",
        "cp = nltk.RegexpParser(grammar)\n",
        "print(cp.parse(ouns))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gdBi2vGllZ2W",
        "outputId": "094515c1-34cb-43f0-b3a9-280b2762f88b"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(S (NP money/NN market/NN fund/NN))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cp = nltk.RegexpParser('CHUNK: {<V.*> <TO> <V.*>}')\n",
        "nltk.download('brown')\n",
        "brown = nltk.corpus.brown\n",
        "chunked = []\n",
        "\n",
        "for sent in brown.tagged_sents():\n",
        "    tree = cp.parse(sent)\n",
        "    for subtree in tree.subtrees():\n",
        "        if subtree.label() == 'CHUNK':\n",
        "            chunked.append(subtree)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NFnRz9-hmYkS",
        "outputId": "1d93efc4-3b8f-4831-9309-fa2df92e0ed7"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package brown to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/brown.zip.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for t in chunked[:5]:\n",
        "    print(t)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OeKCLneWnDAV",
        "outputId": "b7b3c705-d4cb-4c24-d91f-d241932f55d0"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(CHUNK combined/VBN to/TO achieve/VB)\n",
            "(CHUNK continue/VB to/TO place/VB)\n",
            "(CHUNK serve/VB to/TO protect/VB)\n",
            "(CHUNK wanted/VBD to/TO wait/VB)\n",
            "(CHUNK allowed/VBN to/TO place/VB)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#chinking\n",
        "grammar = r\"\"\"\n",
        " NP:\n",
        "  {<.*>+}      # Chunk everything\n",
        "  }<VBD|IN>+{  # Chink sequences of VBD and IN\n",
        " \"\"\"\n",
        "sentence = [(\"the\", \"DT\"), (\"little\", \"JJ\"), (\"yellow\", \"JJ\"),\n",
        "            (\"dog\", \"NN\"), (\"barked\", \"VBD\"), (\"at\", \"IN\"), (\"the\", \"DT\"),\n",
        "            (\"cat\", \"NN\")]\n",
        "cp = nltk.RegexpParser(grammar)\n",
        "print(cp.parse(sentence))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EygvzKjpnNXC",
        "outputId": "c6becf6e-741a-42ec-ed82-96634fdae61f"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(S\n",
            "  (NP the/DT little/JJ yellow/JJ dog/NN)\n",
            "  barked/VBD\n",
            "  at/IN\n",
            "  (NP the/DT cat/NN))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.corpus import conll2000\n",
        "print(conll2000.chunked_sents('train.txt')[99])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XMZrI7QCpGWS",
        "outputId": "fa065ad8-96a3-487a-a48f-d42e9294282a"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(S\n",
            "  (PP Over/IN)\n",
            "  (NP a/DT cup/NN)\n",
            "  (PP of/IN)\n",
            "  (NP coffee/NN)\n",
            "  ,/,\n",
            "  (NP Mr./NNP Stone/NNP)\n",
            "  (VP told/VBD)\n",
            "  (NP his/PRP$ story/NN)\n",
            "  ./.)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(conll2000.chunked_sents('train.txt',chunk_types =['NP'])[99])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LUgw_9W_rHNQ",
        "outputId": "e2503dc9-d2f3-4d5d-bd56-5770d7181fee"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(S\n",
            "  Over/IN\n",
            "  (NP a/DT cup/NN)\n",
            "  of/IN\n",
            "  (NP coffee/NN)\n",
            "  ,/,\n",
            "  (NP Mr./NNP Stone/NNP)\n",
            "  told/VBD\n",
            "  (NP his/PRP$ story/NN)\n",
            "  ./.)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cp = nltk.RegexpParser(\"\")\n",
        "test_sents = conll2000.chunked_sents('test.txt', chunk_types = ['NP'])\n",
        "print(cp.evaluate(test_sents))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yZau4V82rrA3",
        "outputId": "e1f1e4e7-e4da-4fa3-d2d4-14d8bb244b0b"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-17-2425c9069268>:3: DeprecationWarning: \n",
            "  Function evaluate() has been deprecated.  Use accuracy(gold)\n",
            "  instead.\n",
            "  print(cp.evaluate(test_sents))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ChunkParse score:\n",
            "    IOB Accuracy:  43.4%%\n",
            "    Precision:      0.0%%\n",
            "    Recall:         0.0%%\n",
            "    F-Measure:      0.0%%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "grammar = r\"NP: {<[CDJNP].*>+}\"\n",
        "cp = nltk.RegexpParser(grammar)\n",
        "print(cp.evaluate(test_sents))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cT8ggRnHr3VR",
        "outputId": "ec4b4838-dd7f-4cac-a7dc-eee6ebc95bf4"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-18-0eecbc2ed477>:3: DeprecationWarning: \n",
            "  Function evaluate() has been deprecated.  Use accuracy(gold)\n",
            "  instead.\n",
            "  print(cp.evaluate(test_sents))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ChunkParse score:\n",
            "    IOB Accuracy:  87.7%%\n",
            "    Precision:     70.6%%\n",
            "    Recall:        67.8%%\n",
            "    F-Measure:     69.2%%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "grammar = r\"\"\"\n",
        "    NP: {<DT|JJ|NN.*>+}           # Chunk sequences of DT, JJ, NN\n",
        "    PP: {<IN><NP>}                # Chunk prepositions followed by NP\n",
        "    VP: {<VB.*><NP|PP|CLAUSE>+$}  # Chunk verbs and their arguments\n",
        "    CLAUSE: {<NP><VP>}            # Chunk NP, VP\n",
        "\"\"\"\n",
        "cp = nltk.RegexpParser(grammar)\n",
        "sentence = [(\"Mary\", \"NN\"), (\"saw\", \"VBD\"), (\"the\", \"DT\"), (\"cat\", \"NN\"),\n",
        "            (\"sit\", \"VB\"), (\"on\", \"IN\"), (\"the\", \"DT\"), (\"mat\", \"NN\")]\n",
        "print(cp.parse(sentence))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gVIxSnM-sILM",
        "outputId": "56962bf5-ee61-4db8-be55-31962141ef31"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(S\n",
            "  (NP Mary/NN)\n",
            "  saw/VBD\n",
            "  (CLAUSE\n",
            "    (NP the/DT cat/NN)\n",
            "    (VP sit/VB (PP on/IN (NP the/DT mat/NN)))))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tree1 = nltk.Tree('NP', ['Alice'])\n",
        "print(tree1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xYPBlNMIzp8X",
        "outputId": "acd2fe85-73fb-44b8-bfe3-bd4d4a410339"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(NP Alice)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tree2 = nltk.Tree('NP', ['the', 'rabbit'])\n",
        "print(tree2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H4TIVbsE07NW",
        "outputId": "13dd4d01-1326-4288-bcef-70974fcacf39"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(NP the rabbit)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tree3 = nltk.Tree('VP', ['chased', tree2])\n",
        "tree4 = nltk.Tree('S', [tree1, tree3])\n",
        "print(tree4)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6A-iSZTJ0v1A",
        "outputId": "1834efbf-ac68-4399-c897-31d414211a7b"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(S (NP Alice) (VP chased (NP the rabbit)))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tree4.leaves()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O5H_7mbc05sm",
        "outputId": "60fd9b85-b7bf-4819-fa14-1ecd2fd24261"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Alice', 'chased', 'the', 'rabbit']"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#tree3.darw()"
      ],
      "metadata": {
        "id": "H2Ui5Y2n1ELa"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# find relation between entities\n",
        "IN = re.compile(r'.*\\bin\\b(?!\\b.+ing)')\n",
        "for doc in nltk.corpus.ieer.parsed_docs('NYT_19980315'):\n",
        "    for rel in nltk.sem.extract_rels('ORG', 'LOC', doc,\n",
        "                                     corpus = 'ieer', pattern = IN):\n",
        "        print(nltk.sem.rtuple(rel))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BGDV8BtG1FS0",
        "outputId": "089cb664-2914-42cc-e37c-aa84f041e45c"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[ORG: 'WHYY'] 'in' [LOC: 'Philadelphia']\n",
            "[ORG: 'McGlashan &AMP; Sarrail'] 'firm in' [LOC: 'San Mateo']\n",
            "[ORG: 'Freedom Forum'] 'in' [LOC: 'Arlington']\n",
            "[ORG: 'Brookings Institution'] ', the research group in' [LOC: 'Washington']\n",
            "[ORG: 'Idealab'] ', a self-described business incubator based in' [LOC: 'Los Angeles']\n",
            "[ORG: 'Open Text'] ', based in' [LOC: 'Waterloo']\n",
            "[ORG: 'WGBH'] 'in' [LOC: 'Boston']\n",
            "[ORG: 'Bastille Opera'] 'in' [LOC: 'Paris']\n",
            "[ORG: 'Omnicom'] 'in' [LOC: 'New York']\n",
            "[ORG: 'DDB Needham'] 'in' [LOC: 'New York']\n",
            "[ORG: 'Kaplan Thaler Group'] 'in' [LOC: 'New York']\n",
            "[ORG: 'BBDO South'] 'in' [LOC: 'Atlanta']\n",
            "[ORG: 'Georgia-Pacific'] 'in' [LOC: 'Atlanta']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "oVRPTffx238V"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}